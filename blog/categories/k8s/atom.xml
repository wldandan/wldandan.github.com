<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: K8s | Happy Coding, Happy Life]]></title>
  <link href="http://wldandan.github.com/blog/categories/k8s/atom.xml" rel="self"/>
  <link href="http://wldandan.github.com/"/>
  <updated>2019-03-31T12:20:00+08:00</updated>
  <id>http://wldandan.github.com/</id>
  <author>
    <name><![CDATA[wldandan]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[K8s之Service]]></title>
    <link href="http://wldandan.github.com/blog/2019/03/17/k8s-concept-service/"/>
    <updated>2019-03-17T20:45:00+08:00</updated>
    <id>http://wldandan.github.com/blog/2019/03/17/k8s-concept-service</id>
    <content type="html"><![CDATA[<h3>如何访问Pod？</h3>

<p>在非k8s世界中，管理员可以通过在配置文件中指定IP地址或主机名，容许客户端访问，但在k8s中这种方式是行不通的。因为Pod 是有生命周期的，它们可以被创建或销毁。虽然通过 ReplicationController 能够动态地创建Pod，但当Pod被分配到某个节点时，K8s都会为其分配一个IP地址，而该IP地址不总是稳定可依赖的。因此，在 Kubernetes 集群中，如果一组 Pod（称为 backend）为其它 Pod （称为 frontend）提供服务，那么那些 frontend 该如何发现，并连接到这组backend的Pod呢？</p>

<!-- More -->


<h3>Service</h3>

<p>Kubernetes中的Service是一种资源的定义，它将Pod逻辑分组，并提供客户端访问。</p>

<p><img src="/images/k8s/k8s-service-1.png" /></p>

<p> 通过 Label Selector，一组 Pod 能够被暴露为Service，供客户端访问。</p>

<p> <img src="/images/k8s/k8s-service-2.png" /></p>

<p>举个例子，考虑一个图片处理 backend，它运行了3个副本。这些副本是可互换的，通过Service能够解耦frontend与backend的关联。</p>

<blockquote><p>frontend 不需要关心它们调用了哪个 backend 副本。 然而组成这一组 backend 程序的 Pod 实际上可能会发生变化，frontend 客户端不应该也没必要知道，而且也不需要跟踪这一组 backend 的状态。</p></blockquote>

<h3>创建Service</h3>

<p>一个 Service 在 Kubernetes 中是一个 REST 对象，和 Pod 类似。 像所有的 REST 对象一样， Service 定义可以基于 POST 方式，请求 apiserver 创建新的实例。 例如，假定有一组 Pod，它们对外暴露了 9376 端口，同时还被打上 "app=MyApp" 标签。</p>

<p>```yaml
kind: Service
apiVersion: v1
metadata:
  name: my-service
spec:
  selector:</p>

<pre><code>app: MyApp            //根据Label选择一组Pod
</code></pre>

<p>  ports:</p>

<pre><code>- protocol: TCP
  port: 80            //用于访问该Service的端口
  targetPort: 9376    //用于访问容器的端口
</code></pre>

<p>```</p>

<p>接下来，我们可以使用<code>kubectl</code>访问该Service</p>

<p><img src="/images/k8s/k8s-service-3.png" /></p>

<h3>Service如何被外部网络的Client访问</h3>

<p>可以通过如下三种方式，容许外部网络的Client访问Service：</p>

<h4>1.将Service Type置为<code>NodePort</code></h4>

<p>对于NotePort的Service，每个节点(Node)都会打开节点本身的端口，并将该端口上接收到的流量重定向到Service。</p>

<p>```yaml
apiVersion: v1
kind: Service
metadata:
  name: kubia-nodeport
spec:
  type: NodePort             //NodePort类型
  ports:
  - port: 80                 //Service内部访问的地址</p>

<pre><code>targetPort: 8080         //转发给目标Pod的地址
nodePort: 30123          //可访问的nodeport端口
</code></pre>

<p>  selector:</p>

<pre><code>app: kubia
</code></pre>

<p>```</p>

<p>使用NodePort的Service如下图所示：
<img src="/images/k8s/k8s-service-4.png" /></p>

<h4>2.将Service Type设置为<code>LoadBalancer</code></h4>

<p>通过设置<code>LoadBalancer</code>，Service可以通过一个专用的负载均衡器来访问（这个均衡器是运行kubernetes的基础设施提供的）。负载均衡器将流量重定向到所有节点上的节点端口。客户机通过负载均衡器的IP连接到服务。</p>

<p>如果kubernetes在不支持LoadBalancer服务的环境中运行，则不会提供负载均衡器，但该服务的行为仍将类似于NodePort服务。</p>

<p>```yaml</p>

<p>apiVersion: v1
kind: Service
metadata:
  name: kubia-loadbalancer
spec:
  type: LoadBalancer              <br/>
  ports:
  - port: 80</p>

<pre><code>targetPort: 8080
</code></pre>

<p>  selector:</p>

<pre><code>app: kubia
</code></pre>

<p>```</p>

<p>使用如上配置文件创建Service之后，会调用云基础设施，创建负载均衡器并将其IP地址写入Service对象。一旦结束，IP地址将作为Service的外部IP地址列出：</p>

<p>如下图所示：
<img src="/images/k8s/k8s-service-5.png" /></p>

<h4>3.使用<code>Ingress</code>资源</h4>

<p>这是一种完全不同的机制，通过一个IP地址公开多个服务，它在HTTP（网络层7）上运行，因此可以提供比第4层服务更多的功能。</p>

<p>```yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: kubia
spec:
  rules:
  - host: kubia.example.com               //使用domain name访问service</p>

<pre><code>http:
  paths:
  - path: /                           //访问的路径
    backend:
      serviceName: kubia-nodeport     
      servicePort: 80                 
</code></pre>

<p>```</p>

<p>通过Ingress访问Service的流程如下：</p>

<p><img src="/images/k8s/k8s-service-7.png" /></p>

<p>另外，可以通过Ingress访问多个服务：</p>

<p>```yaml
...
  - host: kubia.example.com</p>

<pre><code>http:
  paths:
  - path: /kubia                
    backend:                    
      serviceName: kubia        
      servicePort: 80           
  - path: /foo                  
    backend:                    
      serviceName: bar          
      servicePort: 80           
</code></pre>

<p>```
<img src="/images/k8s/k8s-service-6.png" /></p>

<h3>Service的诊断</h3>

<p>Service是Kubernetes的关键概念，也是令许多开发人员沮丧的根源。我见过许多开发人员耗费大量时间，来弄清楚为什么无法通过Servic IP或fqdn访问到自己的pods。
出于这个原因，简单介绍一下如何对服务进行故障排除。当无法通过Service访问您的pod时，可以从以下列表开始：</p>

<ul>
<li><p>首先，确保从集群内而不是从外部连接到Service的集群IP。</p></li>
<li><p>不要费心Ping Service的IP来确定服务是否可以访问（记住，服务的集群IP是一个虚拟IP，Ping它永远不会工作）。</p></li>
<li><p>如果您已经定义了一个readiness probe，请确保它是成功的；否则Pod将不属于服务的一部分。</p></li>
<li><p>要确认Pod是服务的一部分，请使用kubectl get endpoints检查相应的endpoint对象。</p></li>
<li><p>如果您试图通过其fqdname或其一部分（例如，myservice.mynamespace.svc.cluster.local或myservice.mynamespace）访问服务，但该服务不起作用，请查看是否可以使用其群集IP而不是fqdname访问该服务。</p></li>
<li><p>检查您是否连接到服务公开的端口，而不是目标端口。</p></li>
<li><p>尝试直接连接到pod ip以确认pod是否接受正确端口上的连接。</p></li>
<li><p>如果你甚至不能通过pod的IP访问你的应用，确保你的应用是否绑定到locahost。</p></li>
</ul>


<h3>总结</h3>

<p>Service是K8s中重要的概念，你应该至少明白Service的这些内容：</p>

<ul>
<li><p>通过Lable selector，将一组Pod设置为Service，并为Service配置静态的IP和端口</p></li>
<li><p>Service可以从Cluster内部访问，也可以通过设置为NodePort或者LoadBalancer的方式从外部访问</p></li>
<li><p>Pod可以通过环境变量获取Service的IP和Port，进行访问</p></li>
<li><p>可以将对Pod的关联关系，设置到Endpoint资源中，而简化label selector的方式</p></li>
<li><p>通过设置ServiceType为<code>ExternalName</code>，可以访问外部的Service</p></li>
<li><p>通过Ingress可以设置多个Service被外部访问</p></li>
<li><p>使用pod的readiness probe可以决定pod是否被作为service的一部分</p></li>
<li><p>通过headless Service，可以使用DNS获取Pod的IP</p></li>
</ul>


<h3>参考</h3>

<p>《Kubernetes in action》
《Kubernetes handbook》</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K8s之控制器]]></title>
    <link href="http://wldandan.github.com/blog/2019/03/16/k8s-concept-controller/"/>
    <updated>2019-03-16T20:45:00+08:00</updated>
    <id>http://wldandan.github.com/blog/2019/03/16/k8s-concept-controller</id>
    <content type="html"><![CDATA[<p>Kubernetes中内建了很多controller（控制器），这些相当于一个状态机，用来控制Pod的具体状态和行为。</p>

<!-- More -->


<p>这里已经讲的很详细了，请<a href="https://jimmysong.io/kubernetes-handbook/concepts/deployment.html">参考</a></p>

<h4>Deployment 是什么？</h4>

<p>Deployment为Pod和Replica Set（下一代Replication Controller）提供声明式更新。</p>

<p>您只需要在 Deployment 中描述期望的目标状态，Deployment controller 会帮您将 Pod 和ReplicaSet 的实际状态改变到您的目标状态。</p>

<p>典型的用例如下：</p>

<ul>
<li>使用Deployment来创建ReplicaSet。ReplicaSet在后台创建pod。检查启动状态，看它是成功还是失败。</li>
<li>然后，通过更新Deployment的PodTemplateSpec字段来声明Pod的新状态。这会创建一个新的ReplicaSet，Deployment会按照控制的速率将pod从旧的ReplicaSet移动到新的ReplicaSet中。</li>
<li>如果当前状态不稳定，回滚到之前的Deployment revision。每次回滚都会更新Deployment的revision。</li>
<li>扩容Deployment以满足更高的负载。</li>
<li>暂停Deployment来应用PodTemplateSpec的多个修复，然后恢复上线。</li>
<li>根据Deployment 的状态判断上线是否hang住了。</li>
<li>清除旧的不必要的 ReplicaSet。</li>
</ul>


<h4>创建 Deployment</h4>

<p><code>
$ kubectl create -f https://kubernetes.io/docs/user-guide/nginx-deployment.yaml --record
deployment "nginx-deployment" created
</code></p>

<h4>更新Deployment</h4>

<p><code>
$ kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1
deployment "nginx-deployment" image updated
</code></p>

<h4>检查 Deployment 升级的历史记录</h4>

<p><code>
$ kubectl rollout history deployment/nginx-deployment
deployments "nginx-deployment":
REVISION    CHANGE-CAUSE
1           kubectl create -f https://kubernetes.io/docs/user-guide/nginx-deployment.yaml--record
2           kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1
3           kubectl set image deployment/nginx-deployment nginx=nginx:1.91
</code></p>

<h4>回退到历史版本</h4>

<p><code>
$ kubectl rollout undo deployment/nginx-deployment --to-revision=2
deployment "nginx-deployment" rolled back
</code></p>

<h4>Deployment 扩容</h4>

<p><code>
$ kubectl scale deployment nginx-deployment --replicas 10
deployment "nginx-deployment" scaled
</code></p>

<h4>Deployment 状态</h4>

<p>Deployment 在生命周期中有多种状态。在创建一个新的 ReplicaSet 的时候它可以是 <code>progressing</code> 状态， <code>complete</code> 状态，或者 <code>fail to progress</code> 状态。</p>

<h3>编写 Deployment Spec</h3>

<p>在所有的 Kubernetes 配置中，Deployment 也需要<code>apiVersion</code>，<code>kind</code>和<code>metadata</code>这些配置项。配置文件的通用使用说明查看 <a href="https://kubernetes.io/docs/tasks/run-application/run-stateless-application-deployment/">部署应用</a>，配置容器，和 <a href="https://kubernetes.io/docs/tutorials/object-management-kubectl/object-management/">使用 kubectl 管理资源 </a> 文档。</p>

<h4>Pod Template</h4>

<p> <code>.spec.template</code> 是 <code>.spec</code>中唯一要求的字段。</p>

<p><code>.spec.template</code> 是 <a href="https://kubernetes.io/docs/user-guide/replication-controller/#pod-template">pod template</a>. 它跟 <a href="https://kubernetes.io/docs/user-guide/pods">Pod</a>有一模一样的schema，除了它是嵌套的并且不需要<code>apiVersion</code> 和 <code>kind</code>字段。</p>

<p>另外为了划分Pod的范围，Deployment中的pod template必须指定适当的label（不要跟其他controller重复了，参考<a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment#selector">selector</a>）和适当的重启策略。</p>

<p><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle"><code>.spec.template.spec.restartPolicy</code></a> 可以设置为 <code>Always</code> , 如果不指定的话这就是默认配置。</p>

<h4>Replicas</h4>

<p><code>.spec.replicas</code> 是可以选字段，指定期望的pod数量，默认是1。</p>

<h4>Selector</h4>

<p><code>.spec.selector</code>是可选字段，用来指定 <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels">label selector</a> ，圈定Deployment管理的pod范围。</p>

<p>如果被指定， <code>.spec.selector</code> 必须匹配 <code>.spec.template.metadata.labels</code>，否则它将被API拒绝。如果 <code>.spec.selector</code> 没有被指定， <code>.spec.selector.matchLabels</code> 默认是 <code>.spec.template.metadata.labels</code>。</p>

<p>在Pod的template跟<code>.spec.template</code>不同或者数量超过了<code>.spec.replicas</code>规定的数量的情况下，Deployment会杀掉label跟selector不同的Pod。</p>

<p><strong>注意：</strong> 您不应该再创建其他label跟这个selector匹配的pod，或者通过其他Deployment，或者通过其他Controller，例如ReplicaSet和ReplicationController。否则该Deployment会被把它们当成都是自己创建的。Kubernetes不会阻止您这么做。</p>

<p>如果您有多个controller使用了重复的selector，controller们就会互相打架并导致不正确的行为。</p>

<h4>策略</h4>

<p><code>.spec.strategy</code> 指定新的Pod替换旧的Pod的策略。 <code>.spec.strategy.type</code> 可以是"Recreate"或者是 "RollingUpdate"。"RollingUpdate"是默认值。</p>

<h5>Recreate Deployment</h5>

<p><code>.spec.strategy.type==Recreate</code>时，在创建出新的Pod之前会先杀掉所有已存在的Pod。</p>

<h5>Rolling Update Deployment</h5>

<p><code>.spec.strategy.type==RollingUpdate</code>时，Deployment使用<a href="https://kubernetes.io/docs/tasks/run-application/rolling-update-replication-controller">rolling update</a> 的方式更新Pod 。您可以指定<code>maxUnavailable</code> 和 <code>maxSurge</code> 来控制 rolling update 进程。</p>

<h5>Max Unavailable</h5>

<p><code>.spec.strategy.rollingUpdate.maxUnavailable</code> 是可选配置项，用来指定在升级过程中不可用Pod的最大数量。该值可以是一个绝对值（例如5），也可以是期望Pod数量的百分比（例如10%）。通过计算百分比的绝对值向下取整。如果<code>.spec.strategy.rollingUpdate.maxSurge</code> 为0时，这个值不可以为0。默认值是1。</p>

<p>例如，该值设置成30%，启动rolling update后旧的ReplicatSet将会立即缩容到期望的Pod数量的70%。新的Pod ready后，随着新的ReplicaSet的扩容，旧的ReplicaSet会进一步缩容，确保在升级的所有时刻可以用的Pod数量至少是期望Pod数量的70%。</p>

<h5>Max Surge</h5>

<p><code>.spec.strategy.rollingUpdate.maxSurge</code> 是可选配置项，用来指定可以超过期望的Pod数量的最大个数。该值可以是一个绝对值（例如5）或者是期望的Pod数量的百分比（例如10%）。当<code>MaxUnavailable</code>为0时该值不可以为0。通过百分比计算的绝对值向上取整。默认值是1。</p>

<p>例如，该值设置成30%，启动rolling update后新的ReplicatSet将会立即扩容，新老Pod的总数不能超过期望的Pod数量的130%。旧的Pod被杀掉后，新的ReplicaSet将继续扩容，旧的ReplicaSet会进一步缩容，确保在升级的所有时刻所有的Pod数量和不会超过期望Pod数量的130%。</p>

<h4>Progress Deadline Seconds</h4>

<p><code>.spec.progressDeadlineSeconds</code> 是可选配置项，用来指定在系统报告Deployment的<a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment#failed-deployment">failed progressing</a> ——表现为resource的状态中<code>type=Progressing</code>、<code>Status=False</code>、 <code>Reason=ProgressDeadlineExceeded</code>前可以等待的Deployment进行的秒数。Deployment controller会继续重试该Deployment。未来，在实现了自动回滚后， deployment controller在观察到这种状态时就会自动回滚。</p>

<p>如果设置该参数，该值必须大于 <code>.spec.minReadySeconds</code>。</p>

<h4>Min Ready Seconds</h4>

<p><code>.spec.minReadySeconds</code>是一个可选配置项，用来指定没有任何容器crash的Pod并被认为是可用状态的最小秒数。默认是0（Pod在ready后就会被认为是可用状态）。进一步了解什么什么后Pod会被认为是ready状态，参阅 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes">Container Probes</a>。</p>

<h4>Rollback To</h4>

<p><code>.spec.rollbackTo</code> 是一个可以选配置项，用来配置Deployment回退的配置。设置该参数将触发回退操作，每次回退完成后，该值就会被清除。</p>

<h4>Revision</h4>

<p><code>.spec.rollbackTo.revision</code>是一个可选配置项，用来指定回退到的revision。默认是0，意味着回退到上一个revision。</p>

<h4>Revision History Limit</h4>

<p>Deployment revision history存储在它控制的ReplicaSets中。</p>

<p><code>.spec.revisionHistoryLimit</code> 是一个可选配置项，用来指定可以保留的旧的ReplicaSet数量。该理想值取决于心Deployment的频率和稳定性。如果该值没有设置的话，默认所有旧的Replicaset或会被保留，将资源存储在etcd中，是用<code>kubectl get rs</code>查看输出。每个Deployment的该配置都保存在ReplicaSet中，然而，一旦您删除的旧的RepelicaSet，您的Deployment就无法再回退到那个revison了。</p>

<p>如果您将该值设置为0，所有具有0个replica的ReplicaSet都会被删除。在这种情况下，新的Deployment rollout无法撤销，因为revision history都被清理掉了。</p>

<h4>Paused</h4>

<p><code>.spec.paused</code>是可以可选配置项，boolean值。用来指定暂停和恢复Deployment。Paused和没有paused的Deployment之间的唯一区别就是，所有对paused deployment中的PodTemplateSpec的修改都不会触发新的rollout。Deployment被创建之后默认是非paused。</p>

<h3>资源参考</h3>

<p><a href="https://jimmysong.io/kubernetes-handbook/concepts/deployment.html">k8s handbook - Deployment</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K8s之Pod]]></title>
    <link href="http://wldandan.github.com/blog/2019/03/16/k8s-concept-pod/"/>
    <updated>2019-03-16T19:45:00+08:00</updated>
    <id>http://wldandan.github.com/blog/2019/03/16/k8s-concept-pod</id>
    <content type="html"><![CDATA[<p>Pod是kubernetes中你可以创建和部署的最小也是最简的单位。Pod代表着集群中运行的进程。Pod中封装着应用的容器（1或多个容器）、存储、独立的网络IP，并管理着容器运行的策略选项。</p>

<!-- More -->


<h3>Pod概览</h3>

<p>Pod是一个服务的多个进程的聚合单位，pod通过提供一个更高级别的抽象的方式，极大简化了应用部署管理。
Pod作为一个独立的部署单位，支持横向扩展和复制、协同调度、命运共同体（例如被同时终结），协同复制，资源共享，依赖管理等，Pod会自动的为容器处理这些问题。</p>

<h4>什么是Pod</h4>

<p>Pod是kubernetes中你可以创建和部署的最小也是最简的单位。Pod代表着集群中运行的进程。</p>

<p>Pod中封装着应用的容器（1或多个容器）、存储、独立的网络IP，并管理着容器运行的策略选项。</p>

<p>在Kubrenetes集群中Pod有如下两种使用方式：</p>

<ul>
<li><p>一个Pod中运行一个容器。“每个Pod中一个容器”的模式是最常见的用法；在这种使用方式中，你可以把Pod想象成是单容器的封装，kuberentes管理的是Pod而不是容器。</p></li>
<li><p>在一个Pod中同时运行多个容器。一个Pod中也可以同时封装几个紧密耦合、互相协作的容器，它们之间共享资源。这些在同一个Pod中的容器互相协作，成为一个service单位——如一个容器共享文件，另一个容器更新文件。Pod将这些容器的存储资源作为一个实体来管理。</p></li>
</ul>


<h4>Pod的生命周期</h4>

<p>Pod 的 status 字段是一个 PodStatus 对象，PodStatus中有一个 phase 字段。</p>

<p>下面是 phase 可能的值：</p>

<ul>
<li>挂起（Pending）：Pod 已被 Kubernetes
系统接受，但有一个或者多个容器镜像尚未创建。等待时间包括调度 Pod的时间和通过网络下载镜像的时间，这可能需要花点时间。</li>
<li>运行中（Running）：该 Pod 已经绑定到了一个节点上，Pod 中所有的容器都已被创建。至少有一个容器正在运行，或者正处于启动或重启状态。</li>
<li>成功（Succeeded）：Pod 中的所有容器都被成功终止，并且不会再重启。</li>
<li>失败（Failed）：Pod 中的所有容器都已终止了，并且至少有一个容器是因为失败终止。也就是说，容器以非0状态退出或者被系统终止。</li>
<li>未知（Unknown）：因为某些原因无法取得 Pod 的状态，通常是因为与 Pod 所在主机通信失败。</li>
</ul>


<p>下图是Pod的生命周期示意图，从图中可以看到Pod状态的变化。</p>

<p><img src="/images/k8s/kubernetes-pod-life-cycle.jpg" /></p>

<h4>Pod如何管理多个容器</h4>

<p>Pod中可以同时运行多个容器（独立进程运行）并协同工作。同一个Pod中的容器会自动的分配到同一个node 上运行，同时，同一个Pod中的容器共享存储、网络和依赖，它们总是被同时调度。</p>

<ul>
<li><p>网络</p>

<blockquote><p>每个Pod都会被分配唯一的一个IP地址。Pod中的所有容器共享网络空间，包括IP地址和端口。Pod内部的容器可以使用localhost互相通信。Pod中的容器与外界通信时，必须分配共享网络资源（例如使用宿主机的端口映射）。</p></blockquote></li>
<li><p>存储</p>

<blockquote><p>可以为一个Pod指定多个共享的Volume。Pod中的所有容器都可以访问共享的volume。Volume也可以用来持久化Pod中的存储资源，以防容器重启后文件丢失。</p></blockquote></li>
</ul>


<h3>Pod的管理</h3>

<h4>Pod间发现</h4>

<p>Pod中应用容器共享网络空间（IP地址和端口），因此可以通过localhost互相发现。
Pod中应用容器的hostname被设置成Pod的名字。
Pod中应用容器可以共享volume。volume能够保证pod重启时使用的数据不丢失。</p>

<h4>Pod的使用</h4>

<p>Pod也可以用于垂直应用（例如LAMP），这样使用的动机是为了支持共同调度和协调应用程序，例如：
* 内容管理系统、文件和数据加载器、本地换群管理器等。
* 日志和检查点备份、压缩、旋转、快照等。
* 数据变更观察者、日志和监控适配器、活动发布者等。
* 代理、桥接和适配器等。
* 控制器、管理器、配置器、更新器等。</p>

<h4>Pod的持久性</h4>

<p>Pod不是作为持久化设计的。在调度失败、节点故障、缺少资源或者节点维护的状态下都会失败。</p>

<p>通常，用户不需要手动直接创建Pod，而是应该使用controller（例如Deployments），即使是在创建单个Pod的情况下。Controller可以提供集群级别的自愈功能、复制和升级管理。</p>

<h3>Pod高级特性</h3>

<h4>Pod Preset</h4>

<p>Kubernetes提供了一个准入控制器（PodPreset），当其启用时，Pod Preset 会将应用创建请求传入到该控制器上。因此，<code>Pod Preset</code>是用来在 Pod 被创建的时候向其中注入额外的运行时需求的 API 资源。</p>

<p>您可以使用<code>label selector</code> 来指定为哪些 Pod 应用 Pod Preset。</p>

<h4>Pod和Controller</h4>

<p>Controller可以创建和管理多个Pod，提供副本管理、滚动升级和集群级别的自愈能力。例如，如果一个Node故障，Controller就能自动将该节点上的Pod调度到其他健康的Node上。</p>

<p>包含一个或者多个Pod的Controller示例：</p>

<ul>
<li>Deployment</li>
<li>StatefulSet</li>
<li>DaemonSet</li>
</ul>


<p>通常，Controller会用你提供的Pod Template来创建相应的Pod。</p>

<h4>Init容器</h4>

<p>Init是一种专用的容器，在应用程序容器启动之前运行，包含应用镜像中工具或环境的安装脚本。</p>

<p>Pod 能够有一个或多个先于应用容器启动的 Init 容器。</p>

<p>Init 容器与普通的容器非常像，除了如下两点：
* Init 容器总是运行到成功完成为止。
* 每个 Init 容器都必须在下一个 Init 容器启动之前成功完成。</p>

<p>如果 Pod 的 Init 容器失败，Kubernetes 会不断地重启该 Pod，直到 Init容器成功为止。然而，如果 Pod 对应的 restartPolicy 为 Never，它不会重新启动。</p>

<p>因为 Init 容器具有与应用程序容器分离的单独镜像，所以它们的启动相关代码具有如下优势：</p>

<ul>
<li><p>它们可以包含并运行实用工具，它们可以包含使用工具和定制化代码来安装。例如，创建镜像没必要FROM 另一个镜像，只需要在安装过程中使用类似 sed、 awk、 python 或 dig 这样的工具。</p></li>
<li><p>应用程序镜像可以分离出创建和部署的角色，而没有必要联合它们构建一个单独的镜像。</p></li>
<li><p>Init 容器使用 Linux Namespace，所以相对应用程序容器来说具有不同的文件系统视图。因此，它们能够具有访问 Secret 的权限，而应用程序容器则不能。</p></li>
<li><p>它们必须在应用程序容器启动之前运行完成，所以 Init 容器能够提供一种简单的阻塞或延迟应用容器的启动的方法，直到满足了一组先决条件。</p></li>
</ul>


<h4>Pod 安全策略</h4>

<p>Pod 安全策略 是集群级别的资源，它能够控制 Pod 运行的行为，以及它具有访问什么资源的能力。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K8s之网络]]></title>
    <link href="http://wldandan.github.com/blog/2019/03/15/k8s-concept-network/"/>
    <updated>2019-03-15T23:45:00+08:00</updated>
    <id>http://wldandan.github.com/blog/2019/03/15/k8s-concept-network</id>
    <content type="html"><![CDATA[<p>K8s的网络介绍</p>

<!-- More -->


<h3>K8s集群IP</h3>

<p>Kubernetes集群内部存在三类IP，分别是：</p>

<ul>
<li>Node IP：宿主机的IP地址</li>
<li>Pod IP：使用网络插件创建的IP（如flannel），使跨主机的Pod可以互通</li>
<li>Cluster IP：虚拟IP，通过iptables规则访问服务</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[K8s之集群]]></title>
    <link href="http://wldandan.github.com/blog/2019/03/15/k8s-concept-cluster/"/>
    <updated>2019-03-15T21:45:00+08:00</updated>
    <id>http://wldandan.github.com/blog/2019/03/15/k8s-concept-cluster</id>
    <content type="html"><![CDATA[<p>为了管理异构和不同配置的主机，为了便于Pod的运维管理，Kubernetes中提供了很多集群管理的配置和管理功能，通过namespace划分的空间，通过为node节点创建label和taint用于pod的调度等。</p>

<!-- More -->


<h3>Node</h3>

<p>Node是kubernetes集群的工作节点，可以是物理机也可以是虚拟机。</p>

<h5>Node的状态:</h5>

<ul>
<li><p>Address</p>

<ul>
<li>HostName：可以被kubelet中的--hostname-override参数替代。</li>
<li>ExternalIP：可以被集群外部路由到的IP地址。</li>
<li>InternalIP：集群内部使用的IP，集群外部无法访问。</li>
</ul>
</li>
<li><p>Condition</p>

<ul>
<li>OutOfDisk：磁盘空间不足时为True</li>
<li>Ready：Node controller 40秒内没有收到node的状态报告为Unknown，健康为True，否则为False。</li>
<li>MemoryPressure：当node没有内存压力时为True，否则为False。</li>
<li>DiskPressure：当node没有磁盘压力时为True，否则为False。</li>
</ul>
</li>
<li><p>Capacity</p>

<ul>
<li>CPU</li>
<li>内存</li>
<li>可运行的最大Pod个数</li>
</ul>
</li>
<li><p>Info：节点的一些版本信息，如OS、kubernetes、docker等</p></li>
</ul>


<h3>Namespace</h3>

<p>在一个Kubernetes集群中可以使用namespace创建多个“虚拟集群”，这些集群之间可以完全隔离。如当项目和人员众多的时候可以考虑根据项目属性，例如生产、测试、开发划分不同的namespace。</p>

<p>另外，也可以让一个namespace中的service访问到其他的namespace中的服务。</p>

<h3>Label &amp; Annonication</h3>

<p>Label是附在对象上（例如Pod）的键值对。可以在创建对象的时候指定，也可以在对象创建后随时指定。Labels的值对系统本身并没有什么含义，只是对用户有意义。通过label selector，客户端／用户可以指定一个object集合，通过label selector对object的集合进行操作。</p>

<p>Annotation,可以将Kubernetes资源对象关联到任意的非标识性元数据。使用客户端（如工具和库）可以检索到这些元数据。</p>

<p>Label和Annotation都可以将元数据关联到Kubernetes资源对象。Label主要用于选择对象，可以挑选出满足特定条件的对象。相比之下，annotation 不能用于标识及选择对象。annotation中的元数据可多可少，可以是结构化的或非结构化的，也可以包含label中不允许出现的字符。</p>
]]></content>
  </entry>
  
</feed>
